{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Loading Data","metadata":{}},{"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport nltk\nfrom collections import Counter\nfrom nltk.corpus import stopwords\nfrom nltk.corpus import wordnet\nnltk.download('stopwords')\nnltk.download('omw-1.4')\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score, classification_report, f1_score\n\nfrom tqdm import tqdm\ntqdm.pandas(desc=\"progress-bar\")\nfrom gensim.models import doc2vec, Doc2Vec\nfrom sklearn import utils\nimport gensim\nfrom gensim.models.doc2vec import TaggedDocument\nimport re\n\nimport os\n\nimport warnings\nwarnings.filterwarnings('ignore')\n\"\"\"\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\"\"\"","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-11-09T07:50:01.883332Z","iopub.execute_input":"2022-11-09T07:50:01.883688Z","iopub.status.idle":"2022-11-09T07:50:01.895114Z","shell.execute_reply.started":"2022-11-09T07:50:01.883665Z","shell.execute_reply":"2022-11-09T07:50:01.893313Z"},"trusted":true},"execution_count":110,"outputs":[{"name":"stderr","text":"[nltk_data] Downloading package stopwords to /usr/share/nltk_data...\n[nltk_data]   Package stopwords is already up-to-date!\n[nltk_data] Downloading package omw-1.4 to /usr/share/nltk_data...\n[nltk_data]   Package omw-1.4 is already up-to-date!\n","output_type":"stream"},{"execution_count":110,"output_type":"execute_result","data":{"text/plain":"\"\\nfor dirname, _, filenames in os.walk('/kaggle/input'):\\n    for filename in filenames:\\n        print(os.path.join(dirname, filename))\\n\""},"metadata":{}}]},{"cell_type":"markdown","source":"# Finding and Creating a Dataset (10 hours)","metadata":{}},{"cell_type":"markdown","source":"### To undergo analysis of whether a line indicates the end of a paragraph, we need a lot of data. Thus, there is a readily available dataset on Kaggle with thousands of Wikipedia articles generated via web scrapping that we will use.\n","metadata":{}},{"cell_type":"markdown","source":"### First, we will create an empty dataset with two columns that we for sure know we will need - the line of text we are given, and a boolean indicator for whether that line of text is at the end of a paragraph.","metadata":{}},{"cell_type":"code","source":"wikipedia_data = pd.DataFrame(columns = ['Text', 'End of Paragraph'])","metadata":{"execution":{"iopub.status.busy":"2022-11-09T07:50:01.897136Z","iopub.execute_input":"2022-11-09T07:50:01.897411Z","iopub.status.idle":"2022-11-09T07:50:01.921024Z","shell.execute_reply.started":"2022-11-09T07:50:01.897388Z","shell.execute_reply":"2022-11-09T07:50:01.918950Z"},"trusted":true},"execution_count":111,"outputs":[]},{"cell_type":"markdown","source":"### Currently, the Wikipedia data is not in the form that we need. Looking through the data, we can see that each article has many text files associated with them, indicating the link of the article, external links, etc. \n### We only need to extract one text file from each article - that which is giving us the body of the Wikipedia article. Thus, we will loop through all the articles given and only save the text files with the name 'bodyText.txt' into a list.","metadata":{}},{"cell_type":"code","source":"base_dir = '../input/wikipedia-articles-extracted/Article'\n\ntarget_sub_dir_name = 'bodyText.txt'\n\nbt_paths = []\n\n# walk subdirs under base_dir\nfor root, dirs, files in os.walk(base_dir):\n    for dirs in files:\n        if dirs and target_sub_dir_name in dirs:\n            bt_paths.append(os.path.join(root, target_sub_dir_name))\n","metadata":{"execution":{"iopub.status.busy":"2022-11-09T07:50:01.923026Z","iopub.execute_input":"2022-11-09T07:50:01.923744Z","iopub.status.idle":"2022-11-09T07:50:04.532923Z","shell.execute_reply.started":"2022-11-09T07:50:01.923717Z","shell.execute_reply":"2022-11-09T07:50:04.531761Z"},"trusted":true},"execution_count":112,"outputs":[]},{"cell_type":"markdown","source":"### After we have the list of text files that we need, we will add all the lines of those files into one large list of text.","metadata":{}},{"cell_type":"code","source":"# Adds all files that have the name \"bodyText.txt\" so we can analyze the main body of the article\ntopology_list = []\nfor path in bt_paths:\n    file = open(path,'r')\n    topology_list.append(file.readlines())","metadata":{"execution":{"iopub.status.busy":"2022-11-09T07:50:04.534379Z","iopub.execute_input":"2022-11-09T07:50:04.534826Z","iopub.status.idle":"2022-11-09T07:50:06.144998Z","shell.execute_reply.started":"2022-11-09T07:50:04.534789Z","shell.execute_reply":"2022-11-09T07:50:06.144211Z"},"trusted":true},"execution_count":113,"outputs":[]},{"cell_type":"markdown","source":"### We haven't fully filtered through the data we need yet. So far, the data is in the form of blobs of text, where each element of topology_list is a paragraph of text. We want to filter through the paragraphs and manually add new lines after 80 characters, a standard line length by a variety of platforms. We will create a function to perform this task.\n\n\n### (Aside - this may not be the standard line length of a Wikipedia article on many laptops and computers, yet 80 characters is a somewhat universal standard for which many writers base their line length upon. Furthermore, this increases accessibility for a variety of devices in which many people may be reading Wikipedia on, including tablets and smart phones. We may not be following the exact line lengths of Wikipedia, but this will allow for more general analysis that can be applied to a variety of other sources of data).","metadata":{}},{"cell_type":"code","source":"# Inserts a new line about every 80 characters\ndef insert_newlines(string, every=80):\n    lines = []\n    for i in range(0, len(string), every):\n        lines.append(string[i:i+every])\n    return '\\n'.join(lines)","metadata":{"execution":{"iopub.status.busy":"2022-11-09T07:50:06.146660Z","iopub.execute_input":"2022-11-09T07:50:06.147768Z","iopub.status.idle":"2022-11-09T07:50:06.153195Z","shell.execute_reply.started":"2022-11-09T07:50:06.147743Z","shell.execute_reply":"2022-11-09T07:50:06.151789Z"},"trusted":true},"execution_count":114,"outputs":[]},{"cell_type":"markdown","source":"#### We will then create a new topology list that takes in lines based on the standard line length we have arbitrarily imposed. Before extracting each individual line, we will indicate at the end of each paragraph in topology_list whether it is a paragraph by a key marker we will remove later on. \n\n#### This step is adding an indication of a new line after 80 characters so those lines may be separated later.","metadata":{}},{"cell_type":"code","source":"# New list for each line based on given line length\nnew_topology_list = []\nfor file in topology_list:\n    for paragraph in file:\n        # Adds indication of end of paragraph to end of paragraph\n        paragraph = paragraph + \"[[END]]\"\n        # Adds automatic new line label after every 80 characters\n        new_topology_list.append(insert_newlines(paragraph))","metadata":{"execution":{"iopub.status.busy":"2022-11-09T07:50:06.155188Z","iopub.execute_input":"2022-11-09T07:50:06.155856Z","iopub.status.idle":"2022-11-09T07:50:06.407881Z","shell.execute_reply.started":"2022-11-09T07:50:06.155818Z","shell.execute_reply":"2022-11-09T07:50:06.406108Z"},"trusted":true},"execution_count":115,"outputs":[]},{"cell_type":"markdown","source":"### To now get all the lines without a new line marker, we will split all lines based on the \"\\n\" marker we imposed.","metadata":{}},{"cell_type":"code","source":"all_lines = []\nfor paragraph in new_topology_list:\n    lines = paragraph.split(\"\\n\")\n    for line in lines:\n        all_lines.append(line)","metadata":{"execution":{"iopub.status.busy":"2022-11-09T07:50:06.409162Z","iopub.execute_input":"2022-11-09T07:50:06.409937Z","iopub.status.idle":"2022-11-09T07:50:06.604962Z","shell.execute_reply.started":"2022-11-09T07:50:06.409903Z","shell.execute_reply":"2022-11-09T07:50:06.603635Z"},"trusted":true},"execution_count":116,"outputs":[]},{"cell_type":"markdown","source":"### Thus, we now add all the individual lines to the dataframe's \"Text\" column and initialize all \"End of Paragraph\" boolean values as false before we can edit this later.","metadata":{}},{"cell_type":"code","source":"wikipedia_data['Text'] = [line for line in all_lines]\nwikipedia_data['End of Paragraph'] = False","metadata":{"execution":{"iopub.status.busy":"2022-11-09T07:50:06.606631Z","iopub.execute_input":"2022-11-09T07:50:06.606915Z","iopub.status.idle":"2022-11-09T07:50:06.805251Z","shell.execute_reply.started":"2022-11-09T07:50:06.606891Z","shell.execute_reply":"2022-11-09T07:50:06.804289Z"},"trusted":true},"execution_count":117,"outputs":[]},{"cell_type":"markdown","source":"### We can now analyze the data. In each original paragraph, there was a \"\\n\" marker at the end of the paragraph that showed that it was the end. We then added \"[[END]]\" at the end of each paragraph so that we would not confuse the end of paragraph marking with our arbitrarily-added new lines. As a result, we now have many rows that only have the value of \"[[END]]\". This will prove useful as we develop the 'End of Paragraph' column.","metadata":{}},{"cell_type":"code","source":"display(wikipedia_data)","metadata":{"execution":{"iopub.status.busy":"2022-11-09T07:50:06.806305Z","iopub.execute_input":"2022-11-09T07:50:06.806794Z","iopub.status.idle":"2022-11-09T07:50:06.840765Z","shell.execute_reply.started":"2022-11-09T07:50:06.806767Z","shell.execute_reply":"2022-11-09T07:50:06.839642Z"},"trusted":true},"execution_count":118,"outputs":[{"output_type":"display_data","data":{"text/plain":"                                                     Text  End of Paragraph\n0       John Prophet (1356–1416) was an English mediev...             False\n1       per of the Privy Seal and, Dean of Hereford an...             False\n2       le administrator he remained loyal to all king...             False\n3        cunning.  Although guilty of simony and plura...             False\n4       successfully made the transition from Richard ...             False\n...                                                   ...               ...\n627160           (in French) Béroul's Le Roman de Tristan             False\n627161                                            [[END]]             False\n627162         (in French) Thomas d'Angleterre's  Tristan             False\n627163                                            [[END]]             False\n627164  (in French) Tristan and Iseult, audio version ...             False\n\n[627165 rows x 2 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Text</th>\n      <th>End of Paragraph</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>John Prophet (1356–1416) was an English mediev...</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>per of the Privy Seal and, Dean of Hereford an...</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>le administrator he remained loyal to all king...</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>cunning.  Although guilty of simony and plura...</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>successfully made the transition from Richard ...</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>627160</th>\n      <td>(in French) Béroul's Le Roman de Tristan</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>627161</th>\n      <td>[[END]]</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>627162</th>\n      <td>(in French) Thomas d'Angleterre's  Tristan</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>627163</th>\n      <td>[[END]]</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>627164</th>\n      <td>(in French) Tristan and Iseult, audio version ...</td>\n      <td>False</td>\n    </tr>\n  </tbody>\n</table>\n<p>627165 rows × 2 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"### If we see a row that has the value \"[[END]]\", we know that the previous row must have been the last line in the paragraph. Thus, we can loop through the 'Text' column and assign the previous row as being the end of the paragraph if the current row has the value of '[[END]]'","metadata":{}},{"cell_type":"code","source":"for ind, text in enumerate(wikipedia_data['Text']):\n    if \"[[END]]\" in text:\n        # assign previous row's value for end of paragraph as true\n        wikipedia_data.loc[ind - 1, \"End of Paragraph\"] = True","metadata":{"execution":{"iopub.status.busy":"2022-11-09T07:50:06.842257Z","iopub.execute_input":"2022-11-09T07:50:06.842682Z","iopub.status.idle":"2022-11-09T07:50:47.161995Z","shell.execute_reply.started":"2022-11-09T07:50:06.842649Z","shell.execute_reply":"2022-11-09T07:50:47.160228Z"},"trusted":true},"execution_count":119,"outputs":[]},{"cell_type":"markdown","source":"### And then we can remove the row with \"[[END]]\" so that it will not interfere with our analysis (as well as remove any general empty rows","metadata":{}},{"cell_type":"code","source":"# remove rows that have the value \"[[END]]\" in them\nwikipedia_data = wikipedia_data[wikipedia_data['Text'].str.contains(\"END\") == False]\n# remove rows with empty strings\nwikipedia_data = wikipedia_data[wikipedia_data['Text'] != \"\"]\n# resetting indices after removing elements\nwikipedia_data = wikipedia_data.reset_index()","metadata":{"execution":{"iopub.status.busy":"2022-11-09T07:50:47.165747Z","iopub.execute_input":"2022-11-09T07:50:47.166055Z","iopub.status.idle":"2022-11-09T07:50:47.565584Z","shell.execute_reply.started":"2022-11-09T07:50:47.166031Z","shell.execute_reply":"2022-11-09T07:50:47.564120Z"},"trusted":true},"execution_count":120,"outputs":[]},{"cell_type":"markdown","source":"### We have now created the dataset we need and can perform feature engineering. ","metadata":{}},{"cell_type":"code","source":"display(wikipedia_data)","metadata":{"execution":{"iopub.status.busy":"2022-11-09T07:50:47.567880Z","iopub.execute_input":"2022-11-09T07:50:47.568221Z","iopub.status.idle":"2022-11-09T07:50:47.580856Z","shell.execute_reply.started":"2022-11-09T07:50:47.568196Z","shell.execute_reply":"2022-11-09T07:50:47.579395Z"},"trusted":true},"execution_count":121,"outputs":[{"output_type":"display_data","data":{"text/plain":"         index                                               Text  \\\n0            0  John Prophet (1356–1416) was an English mediev...   \n1            1  per of the Privy Seal and, Dean of Hereford an...   \n2            2  le administrator he remained loyal to all king...   \n3            3   cunning.  Although guilty of simony and plura...   \n4            4  successfully made the transition from Richard ...   \n...        ...                                                ...   \n416593  627154              Tristan page from the Camelot Project   \n416594  627156        Bibliography of Modern Tristania in English   \n416595  627158   Tristan and Iseult public domain audiobook at...   \n416596  627160           (in French) Béroul's Le Roman de Tristan   \n416597  627162         (in French) Thomas d'Angleterre's  Tristan   \n\n        End of Paragraph  \n0                  False  \n1                  False  \n2                  False  \n3                  False  \n4                  False  \n...                  ...  \n416593              True  \n416594              True  \n416595              True  \n416596              True  \n416597              True  \n\n[416598 rows x 3 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>index</th>\n      <th>Text</th>\n      <th>End of Paragraph</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>John Prophet (1356–1416) was an English mediev...</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>per of the Privy Seal and, Dean of Hereford an...</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>le administrator he remained loyal to all king...</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>cunning.  Although guilty of simony and plura...</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>successfully made the transition from Richard ...</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>416593</th>\n      <td>627154</td>\n      <td>Tristan page from the Camelot Project</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>416594</th>\n      <td>627156</td>\n      <td>Bibliography of Modern Tristania in English</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>416595</th>\n      <td>627158</td>\n      <td>Tristan and Iseult public domain audiobook at...</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>416596</th>\n      <td>627160</td>\n      <td>(in French) Béroul's Le Roman de Tristan</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>416597</th>\n      <td>627162</td>\n      <td>(in French) Thomas d'Angleterre's  Tristan</td>\n      <td>True</td>\n    </tr>\n  </tbody>\n</table>\n<p>416598 rows × 3 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"# Feature Engineering","metadata":{}},{"cell_type":"markdown","source":"### Let's brainstorm some features that may be an indication that the line we read is the end of a paragraph. Some immediate features that come to mind are the length of the line (we can create two separate variables for the length and whether the length is short) and whether the line ends with punctuation such as '.' or '!'. Let's create functions to add these features.","metadata":{}},{"cell_type":"code","source":"# Creating a feature that marks the length of the line\nwikipedia_data['Line Length'] = wikipedia_data['Text'].apply(lambda x: len(x))\n\n# Creating a feature that determines whether the length of the line is significantly smaller\nwikipedia_data['Short Length Line'] = wikipedia_data['Text'].apply(lambda x: len(x) < 70)\n\n# Creating a feature that determines whether the line ends with punctuation\nwikipedia_data['Ends with Punctuation'] = wikipedia_data['Text'].apply(lambda x: x[-1] is '.' or x[-1] is '!')\n\n# Tones with ending sentences ?\ndisplay(wikipedia_data)","metadata":{"execution":{"iopub.status.busy":"2022-11-09T07:50:47.582917Z","iopub.execute_input":"2022-11-09T07:50:47.583238Z","iopub.status.idle":"2022-11-09T07:50:47.980068Z","shell.execute_reply.started":"2022-11-09T07:50:47.583214Z","shell.execute_reply":"2022-11-09T07:50:47.978716Z"},"trusted":true},"execution_count":122,"outputs":[{"output_type":"display_data","data":{"text/plain":"         index                                               Text  \\\n0            0  John Prophet (1356–1416) was an English mediev...   \n1            1  per of the Privy Seal and, Dean of Hereford an...   \n2            2  le administrator he remained loyal to all king...   \n3            3   cunning.  Although guilty of simony and plura...   \n4            4  successfully made the transition from Richard ...   \n...        ...                                                ...   \n416593  627154              Tristan page from the Camelot Project   \n416594  627156        Bibliography of Modern Tristania in English   \n416595  627158   Tristan and Iseult public domain audiobook at...   \n416596  627160           (in French) Béroul's Le Roman de Tristan   \n416597  627162         (in French) Thomas d'Angleterre's  Tristan   \n\n        End of Paragraph  Line Length  Short Length Line  \\\n0                  False           80              False   \n1                  False           80              False   \n2                  False           80              False   \n3                  False           80              False   \n4                  False           80              False   \n...                  ...          ...                ...   \n416593              True           37               True   \n416594              True           43               True   \n416595              True           55               True   \n416596              True           40               True   \n416597              True           42               True   \n\n        Ends with Punctuation  \n0                       False  \n1                       False  \n2                       False  \n3                       False  \n4                       False  \n...                       ...  \n416593                  False  \n416594                  False  \n416595                  False  \n416596                  False  \n416597                  False  \n\n[416598 rows x 6 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>index</th>\n      <th>Text</th>\n      <th>End of Paragraph</th>\n      <th>Line Length</th>\n      <th>Short Length Line</th>\n      <th>Ends with Punctuation</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>John Prophet (1356–1416) was an English mediev...</td>\n      <td>False</td>\n      <td>80</td>\n      <td>False</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>per of the Privy Seal and, Dean of Hereford an...</td>\n      <td>False</td>\n      <td>80</td>\n      <td>False</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>le administrator he remained loyal to all king...</td>\n      <td>False</td>\n      <td>80</td>\n      <td>False</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>cunning.  Although guilty of simony and plura...</td>\n      <td>False</td>\n      <td>80</td>\n      <td>False</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>successfully made the transition from Richard ...</td>\n      <td>False</td>\n      <td>80</td>\n      <td>False</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>416593</th>\n      <td>627154</td>\n      <td>Tristan page from the Camelot Project</td>\n      <td>True</td>\n      <td>37</td>\n      <td>True</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>416594</th>\n      <td>627156</td>\n      <td>Bibliography of Modern Tristania in English</td>\n      <td>True</td>\n      <td>43</td>\n      <td>True</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>416595</th>\n      <td>627158</td>\n      <td>Tristan and Iseult public domain audiobook at...</td>\n      <td>True</td>\n      <td>55</td>\n      <td>True</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>416596</th>\n      <td>627160</td>\n      <td>(in French) Béroul's Le Roman de Tristan</td>\n      <td>True</td>\n      <td>40</td>\n      <td>True</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>416597</th>\n      <td>627162</td>\n      <td>(in French) Thomas d'Angleterre's  Tristan</td>\n      <td>True</td>\n      <td>42</td>\n      <td>True</td>\n      <td>False</td>\n    </tr>\n  </tbody>\n</table>\n<p>416598 rows × 6 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"### We can also try to find the most common words used in lines that indicate the end of a paragraph and compare them to other lines. Let's see if there are any significant differences.","metadata":{}},{"cell_type":"code","source":"# List of all words in text where the lines are not the end of the paragraph\nnot_paragraph = []\n# List of all words in text where the lines are the end of the paragraph\nparagraph = []\n\n# Find most common words in both lines that are at the end of a paragraph and those that aren't\nfor ind, text in enumerate(wikipedia_data['Text']):\n    # Gets unique list of words to analyze\n    for txt in list(set(text.split())):\n        txt = txt.lower()\n        if txt not in stopwords.words('english') and len(txt) > 1 and wordnet.synsets(txt):\n            if wikipedia_data.loc[ind, 'End of Paragraph'] and txt not in paragraph:\n                paragraph.append(txt)\n            elif not wikipedia_data.loc[ind, 'End of Paragraph'] and txt not in not_paragraph:\n                not_paragraph.append(txt)\n                \n# Pass the lists to instance of Counter class\nnot_paragraph_counter = Counter(not_paragraph)\nparagraph_counter = Counter(paragraph)\n\n# Get 500 most common words for each list \nmost_occur_not_paragraph = not_paragraph_counter.most_common(500)\nmost_occur_paragraph = paragraph_counter.most_common(500)\n\n#maybe contains numbers ? more numbers at end?\n# create column that counts 500 top words and returns whether that text contains a word in either set\n\n# isolate most common words that are only at the end of paragraph list \n#only_end_of_paragraph = [word for word in list(zip(*most_occur_paragraph)) if word not in list(zip(*most_occur_not_paragraph))] \nonly_end_of_paragraph = list(set(zip(*most_occur_not_paragraph)).difference(zip(*most_occur_paragraph)))                         \nprint(\"Most common words only at lines that are at the end of a paragraph: %s\" %(only_end_of_paragraph))\n\nprint(\"\\n\\n\\n\")\n\n# isolate most common words that are only at the not end of paragraph list\n#only_not_end_of_paragraph = [word for word in list(zip(*most_occur_not_paragraph)) if word not in list(zip(*most_occur_paragraph))]\nonly_not_end_of_paragraph = list(set(zip(*most_occur_paragraph)).difference(zip(*most_occur_not_paragraph)))   \nprint(\"Most common words only at lines that are not at the end of a paragraph: %s\" %(only_not_end_of_paragraph))","metadata":{"execution":{"iopub.status.busy":"2022-11-09T07:50:47.982261Z","iopub.execute_input":"2022-11-09T07:50:47.983181Z","iopub.status.idle":"2022-11-09T08:04:36.806530Z","shell.execute_reply.started":"2022-11-09T07:50:47.983130Z","shell.execute_reply":"2022-11-09T08:04:36.805265Z"},"trusted":true},"execution_count":123,"outputs":[{"name":"stdout","text":"Most common words only at lines that are at the end of a paragraph: [('henry', 'prophet', 'john', 'medieval', 'english', 'secretary', 'king', 'hereford', 'distinguished', 'dean', 'privy', 'seal', 'le', 'administrator', 'kings', 'remained', 'loyal', 'mix', 'guilty', 'simony', 'made', 'transition', 'successfully', 'court', 'extravagant', 'educated', 'university', 'entered', 'ordained', 'holy', 'priest', 'th', 'clerk', 'served', 'office', 'onwards', 'appointed', 'chaplain', 'archbishop', 'council', 'time', 'prebendary', 'converted', 'diocese', 'habit', 'cathedral', 'continued', 'gifts', 'curios', 'anomalous', 'another', 'nonetheless', 'servants', 'clever', 'crown', 'hard', 'commonly', 'promoted', 'rewarded', 'energetic', 'royal', 'pursuit', 'agenda', 'first', 'system', 'introducing', 'register', 'collation', 'november', 'ran', 'kind', 'thence', 'portion', 'appertaining', 'upper', 'saints', 'church', 'parish', 'hall', 'orpington', 'kent', 'rector', 'also', 'preferred', 'deanery', 'year', 'following', 'elevated', 'lawless', 'responsible', 'city', 'probably', 'bishop', 'knew', 'master', 'already', 'feud', 'precincts', 'ongoing', 'part', 'spilled', 'chapter', 'street', 'chair', 'later', 'visitation', 'ed', 'defrocking', 'investigate', 'possible', 'instructions', 'included', 'hospital', 'administered', 'days', 'conditions', 'replaced', 'experienced', 'jury', 'new', 'sealed', 'submitted', 'ordinances', 'palace', 'confirmation', '16', 'december', 'provide', 'care', 'infirm', 'cure', 'proper', 'standards', 'food', 'laid', 'minimum', 'diet', 'discipline', 'guarantee', 'board', 'ensure', 'chaplains', 'pay', 'stipend', 'wear', 'white', 'well', 'uniform', 'mainly', 'vested', 'chosen', 'retained', 'local', 'yet', 'men', 'order', 'removed', 'late', 'early', '15th', '14th', 'national', 'masters', 'centuries', 'mansion', 'sustained', 'intended', 'layout', 'central', 'years', '400', 'next', 'administrative', 'extensive', 'essay', 'reform', 'plan', 'lower', 'robert', 'estate', 'fellow', 'ambitious', 'priests', 'newly', 'april', 'eight', 'build', 'chantry', 'founded', 'college', 'union', 'eve', 'mass', 'premiere', 'celebrate', 'weighty', 'accepted', 'responsibility', 'episcopal', 'patronage', 'lead', 'allowed', 'perpetuity', 'reduction', 'small', 'project', 'size', 'chapel', 'underscored', 'shrewd', 'rents', 'coppice', 'acres', 'woodland', 'little', '27', '70', 'came', 'tithe', 'use', 'proposed', 'ted', 'personal', 'built', 'stonemason', 'son', 'great', 'fellows', 'stone', 'rise', 'despite', 'enjoy', 'iv', 'recalled', 'salary', 'york', 'retainer', 'minster', 'lord', 'say', 'representatives', 'sent', 'inform', 'called', 'matter', 'parliament', 'expect', 'release', 'papal', 'licence', 'allow', 'pope', 'duties', 'relinquish', 'asap', 'prebendaries', 'several', 'held', 'lincoln', 'followed', 'buzzard', 'resign', 'fulfilled', 'collated', 'death', 'never', 'old', 'reside', 'building', 'ambition', 'mem', 'farmyard', 'barn', 'ad', 'pro', 'thornton', 'house', 'simultaneously', 'refurbished', 'charters', 'known', 'bee', 'unusual', 'peculiar', 'always', 'judging', 'ecclesiastical', 'matters', 'confidence', 'retaining', 'keeper', 'ce', 'one', 'last', 'ill', 'meetings', 'father', 'fell', 'february', 'met', 'blackfriars', 'negotiations', 'discussed', 'failure', 'war', 'certainty', 'safeguard', 'seas', 'borders', 'wanted', 'castle', 'repair', 'full', 'report', 'expenditures', 'state', 'finances', 'westminster', 'officers', 'attended', 'disciplined', 'particularly', 'key', 'christian', 'calendar', 'feast', 'like', '21', 'discuss', 'ambassadors', 'paris', 'returned', 'safety', 'peace', 'find', 'settlement', 'failed', 'charles', 'advice', 'monday', 'altered', 'june', 'october', 'courtiers', 'fleet', 'stepped', 'complete', 'victory', 'invaded', 'elusive', 'achieved', '200', 'within', 'chain', 'control', 'military', 'naval', 'command', 'strong', 'north', 'travel', 'outside', 'buried', 'marked', 'sir', 'monumental', 'brass', 'executors', 'thomas', 'nephew', 'patent', 'monuments', 'scott', 'proceedings', 'nicholas', 'harris', 'valor', 'record', 'middle', 'england', 'biographical', 'oxford', 'borough', 'transactions', 'history', 'pr', 'navy', 'britain', 'jones', 'institutional', 'char', 'medicine', 'cultural', 'meaning', 'reign', 'located', 'gate', 'tower', 'south', 'skyscraper', 'commenced', 'aug', 'topped', 'may', 'construction', 'sheffield', 'tallest', 'arts', 'surpassing', 'metres', '101', 'con', 'place', 'heart', 'centrepiece', 'ne', 'ease', 'occupied', 'site', 'ta', 'constructed', 'town', 'way', 'demolished', 'subsequently', 'make', 'originally', 'gardens', 'extensions', 'nicknamed', 'two', 'egg', 'box', 'section', 'cake', 'due', 'eastern', 'wedding', 'remainder', 'became', 'western', 'buildings', 'offices', 'alongside', 'contrasting', '1890s', 'revival', 'style', 'design', 'renaissance', 'ho', 'namely', 'along', 'short', 'distance', 'extension', '1970s', 'relocated', 'left', 'emptied', 'square', 'millennium', 'completion', 'attention', 'turned', 'winter', 'planning', 'permission', 'granted', 'officially', 'beginning', 'work', 'commencing', 'development', 'process', 'total', 'includes', 'apartments', 'adjacent', 'named', 'main', 'pa', 'ground-floor', 'conservatively', 'linked', 'surrounding', 'li', 'complementing', 'grade', 'official', 'website', 'modern', 'according', 'company', 'leading', 'announced', 'july', 'gone', 'group', 'insolvency')]\n\n\n\n\nMost common words only at lines that are not at the end of a paragraph: [('servant', 'indispensable', 'quell', 'rebellion', 'legal', 'unique', 'breaches', 'including', 'blasphemy', 'voyage', 'make', 'gate', 'chaplain', 'state', 'secretary', 'privy', 'lord', 'seal', 'councillor', 'york', 'dean', 'hereford', 'chapter', 'common', 'court', 'pleas', 'bishop', 'register', 'henry', 'reign', 'iv', 'england', 'medieval', 'history', 'chapters', 'administrative', 'council', 'yale', 'christopher', 'age', 'field', 'naturalists', 'welfare', 'ii', 'english', 'sheffield', 'redevelopment', 'city', 'proved', 'throughout', 'hall', 'controversial', 'former', 'named', 'egg', 'box', 'late', 'window', 'ground-floor', 'linked', 'pizza', 'ng', 'place', 'portion', 'end', 'southeast', 'rather', 'royal', 'american', 'palace', 'nt', 'damage', 'people', 'hawaiian', 'native', 'uss', 'arizona', 'climate', 'chart', '14', '27', '18', '19', '105', '17', '30', '29', '31', '21', '22', '10', '28', '23', '95', '25', '20', 'average', 'temperatures', 'totals', 'precipitation', 'conversion', 'imperial', '81', '64', '66', '63', '86', '84', '88', '70', '72', '82', '73', '77', '68', 'inches', 'sea', 'rising', 'feet', 'east', 'anywhere', 'go', 'beach', 'ala', 'bay', 'ko', 'park', 'sandy', 'sunset', 'aloha', 'tower', 'disney', 'spa', 'resort', 'banzai', 'pipeline', 'museum', 'head', 'diamond', 'dole', 'plantation', 'foster', 'garden', 'botanical', 'point', 'honolulu', 'art', 'ranch', 'hawaii', 'temple', 'pali', 'lookout', 'lighthouse', 'national', 'cemetery', 'pacific', 'memorial', 'shore', 'north', 'harbor', 'pearl', 'center', 'polynesian', 'cultural', 'triple', 'surfing', 'crown', 'missouri', 'temples', 'valley', 'aquarium', 'audubon', 'players', 'around', 'drive', 'miles', 'er', 'prominently', '50', 'first', 'movie', 'takes', 'installed', 'planned', 'island', 'beaches', 'university', 'covering', 'military', 'television', 'british', 'directing', 'brown', 'roll', 'monthly', 'atlantic', 'ltd.', 'days', 'great', '100', 'war', 'fought', 'new', 'page', 'web', 'receiving', 'also', 'super', 'est', 'bowl', 'comeback', 'touchdown', 'yards', 'one', 'ongoing', 'concerns', 'along', 'rushing', 'high', 'see', 'playing', 'grandson', 'miami', 'dolphins', 'sports', 'profile', 'qualified', 'melbourne', 'john', 'dentist', 'dentistry', 'spring', 'building', 'built', 'department', 'ic', 'general', 'care', 'members', 'emergency', 'dental', 'pensioner', 'concession', 'services', 'victoria', 'health', 'oral', 'bachelor', 'scholarship', 'undergraduate', 'approval', 'prior', 'palestine', 'lans', 'became', 'clear', 'conditions', 'formal', 'arab', 'hussein', 'considered', 'indigenous', 'ice', 'economic', 'interfere', 'freedom', 'political', 'peace', 'conference', 'upcoming', 'statements', 'foreign', 'zionist', 'delegation', 'agreement', 'dr.', 'emir', 'weizmann', 'january', 'agreed', 'hundred', 'nineteen', 'nine', 'paris', 'mission', 'jewish', 'home', 'short-lived', 'kingdom', 'behalf', 'slightly', 'added', 'inaccurate', 'memorandum', 'submitted', 'side', 'mutual', 'parties', 'consideration', 'supreme', 'ore', 'quoted', 'march', 'interview', 'le', 'faisal', 'signed', 'regard', 'moderate', 'supporter', 'private', 'public', 'disavow', 'disclosed', 'void', 'losing', 'syria', 'hat', 'right', 'book', 'process', 'middle', 'proposals', 'list', 'law', '44', 'taylor', 'external', 'link', 'full', 'united', 'nations', 'reference', 'archived', 'announced', 'october', 'inductees', 'names', 'official', 'fame', 'george', 'judith', 'anderson', 'astaire', 'bailey', 'bankhead', 'barrymore', 'norman', 'bel', 'irving', 'berlin', 'bernstein', 'leonard', 'edwin', 'booth', 'cornell', 'coward', 'fontanne', 'gershwin', 'ira', 'gish', 'oscar', 'hammerstein', 'moss', 'hart', 'hayes', 'helen', 'lawrence', 'frank', 'lunt', 'alfred', 'merman', 'jean', 'eugene', \"o'neill\", 'rodgers', 'tennessee', 'williams', 'site', 'may', 'november', 'tyranny', 'marked', 'start', 'roman', 'colony', 'notably', 'es', 'no.', 'concrete', 'till', 'largest', 'companions', 'way', 'journey', 'novel', 'riding', 'gulf', 'across', 'emperor', 'horse', 'prolonged', 'title', 'gave', 'transferred', 'later', 'still', 'large', 'erns', 'sunday', 'took', 'centuries', 'studied', 'charles', 'visited', 'overlooking', 'purpose-built', 'campus', 'hilltop', 'allow', 'attractions', 'colosseum', 'flow', 'augustus', 'included', 'water', 'working', 'ill', 'old', 'used', 'today', 'road', 'near', 'excavated', 'blood', 'station', 'campania', 'monte', 'naples', 'patron', 'saint', 'executed', 'born', 'film', 'grew', 'apostle', 'landed', 'baroque', 'died', 'dictator', 'villa', 'municipality', 'taken', 'plus', 'georgian', 'king', 'culminated', 'christianization', 'armenian', 'invaded', 'problem', 'interests', 'us', 'abraham', 'catholicos', 'according', 'russians', 'uzbekistan', 'regime', 'deported', 'community', 'left', 'georgia', 'armenians', 'belgian', 'women', 'participated', 'charter', 'penn', 'school', 'rivalry', 'football', 'belfry', 'iconic', 'quickly', 'made', 'pts', 'co-educate', 'episcopal', 'primate', 'nd', 'started', 'graduating', 'co-ed', 'class', 'girls', 'dating', 'back', 'kind', 'staple')]\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### We can take in this input and create separate boolean columns for whether words in the given text are found in the list of most common words occurring at the end of a paragraph and the list of most common words occurring in the middle or beginning of the paragraph (exclusive).","metadata":{}},{"cell_type":"code","source":"# Turns tuple input into list\nonly_end_of_paragraph_list = list(only_end_of_paragraph[0])\nonly_not_end_of_paragraph_list = list(only_not_end_of_paragraph[0])","metadata":{"execution":{"iopub.status.busy":"2022-11-09T08:04:36.807904Z","iopub.execute_input":"2022-11-09T08:04:36.808321Z","iopub.status.idle":"2022-11-09T08:04:36.815035Z","shell.execute_reply.started":"2022-11-09T08:04:36.808286Z","shell.execute_reply":"2022-11-09T08:04:36.813628Z"},"trusted":true},"execution_count":124,"outputs":[]},{"cell_type":"code","source":"# Creates column based on whether the text contains words common at lines that signal the end of paragraph\nwikipedia_data['Contains Common Word at End'] = wikipedia_data['Text'].apply(lambda x: any(word in str(x) for word in only_end_of_paragraph_list))\n# Creates column based on whether the text contains words common at lines not at the end of the paragraph\nwikipedia_data['Contains Common Word NOT at End'] = wikipedia_data['Text'].apply(lambda x: any(word in str(x) for word in only_not_end_of_paragraph_list))","metadata":{"execution":{"iopub.status.busy":"2022-11-09T08:04:36.817133Z","iopub.execute_input":"2022-11-09T08:04:36.817651Z","iopub.status.idle":"2022-11-09T08:04:57.370874Z","shell.execute_reply.started":"2022-11-09T08:04:36.817615Z","shell.execute_reply":"2022-11-09T08:04:57.369769Z"},"trusted":true},"execution_count":125,"outputs":[]},{"cell_type":"markdown","source":"### Now we have many key features we can use to build a machine learning model.","metadata":{}},{"cell_type":"code","source":"display(wikipedia_data)","metadata":{"execution":{"iopub.status.busy":"2022-11-09T08:04:57.372418Z","iopub.execute_input":"2022-11-09T08:04:57.372788Z","iopub.status.idle":"2022-11-09T08:04:57.391388Z","shell.execute_reply.started":"2022-11-09T08:04:57.372762Z","shell.execute_reply":"2022-11-09T08:04:57.390267Z"},"trusted":true},"execution_count":126,"outputs":[{"output_type":"display_data","data":{"text/plain":"         index                                               Text  \\\n0            0  John Prophet (1356–1416) was an English mediev...   \n1            1  per of the Privy Seal and, Dean of Hereford an...   \n2            2  le administrator he remained loyal to all king...   \n3            3   cunning.  Although guilty of simony and plura...   \n4            4  successfully made the transition from Richard ...   \n...        ...                                                ...   \n416593  627154              Tristan page from the Camelot Project   \n416594  627156        Bibliography of Modern Tristania in English   \n416595  627158   Tristan and Iseult public domain audiobook at...   \n416596  627160           (in French) Béroul's Le Roman de Tristan   \n416597  627162         (in French) Thomas d'Angleterre's  Tristan   \n\n        End of Paragraph  Line Length  Short Length Line  \\\n0                  False           80              False   \n1                  False           80              False   \n2                  False           80              False   \n3                  False           80              False   \n4                  False           80              False   \n...                  ...          ...                ...   \n416593              True           37               True   \n416594              True           43               True   \n416595              True           55               True   \n416596              True           40               True   \n416597              True           42               True   \n\n        Ends with Punctuation  Contains Common Word at End  \\\n0                       False                         True   \n1                       False                         True   \n2                       False                         True   \n3                       False                         True   \n4                       False                         True   \n...                       ...                          ...   \n416593                  False                         True   \n416594                  False                         True   \n416595                  False                         True   \n416596                  False                         True   \n416597                  False                         True   \n\n        Contains Common Word NOT at End  \n0                                  True  \n1                                  True  \n2                                  True  \n3                                  True  \n4                                  True  \n...                                 ...  \n416593                             True  \n416594                             True  \n416595                             True  \n416596                            False  \n416597                             True  \n\n[416598 rows x 8 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>index</th>\n      <th>Text</th>\n      <th>End of Paragraph</th>\n      <th>Line Length</th>\n      <th>Short Length Line</th>\n      <th>Ends with Punctuation</th>\n      <th>Contains Common Word at End</th>\n      <th>Contains Common Word NOT at End</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>John Prophet (1356–1416) was an English mediev...</td>\n      <td>False</td>\n      <td>80</td>\n      <td>False</td>\n      <td>False</td>\n      <td>True</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>per of the Privy Seal and, Dean of Hereford an...</td>\n      <td>False</td>\n      <td>80</td>\n      <td>False</td>\n      <td>False</td>\n      <td>True</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>le administrator he remained loyal to all king...</td>\n      <td>False</td>\n      <td>80</td>\n      <td>False</td>\n      <td>False</td>\n      <td>True</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>cunning.  Although guilty of simony and plura...</td>\n      <td>False</td>\n      <td>80</td>\n      <td>False</td>\n      <td>False</td>\n      <td>True</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>successfully made the transition from Richard ...</td>\n      <td>False</td>\n      <td>80</td>\n      <td>False</td>\n      <td>False</td>\n      <td>True</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>416593</th>\n      <td>627154</td>\n      <td>Tristan page from the Camelot Project</td>\n      <td>True</td>\n      <td>37</td>\n      <td>True</td>\n      <td>False</td>\n      <td>True</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>416594</th>\n      <td>627156</td>\n      <td>Bibliography of Modern Tristania in English</td>\n      <td>True</td>\n      <td>43</td>\n      <td>True</td>\n      <td>False</td>\n      <td>True</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>416595</th>\n      <td>627158</td>\n      <td>Tristan and Iseult public domain audiobook at...</td>\n      <td>True</td>\n      <td>55</td>\n      <td>True</td>\n      <td>False</td>\n      <td>True</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>416596</th>\n      <td>627160</td>\n      <td>(in French) Béroul's Le Roman de Tristan</td>\n      <td>True</td>\n      <td>40</td>\n      <td>True</td>\n      <td>False</td>\n      <td>True</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>416597</th>\n      <td>627162</td>\n      <td>(in French) Thomas d'Angleterre's  Tristan</td>\n      <td>True</td>\n      <td>42</td>\n      <td>True</td>\n      <td>False</td>\n      <td>True</td>\n      <td>True</td>\n    </tr>\n  </tbody>\n</table>\n<p>416598 rows × 8 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"# Building and Evaluating a Model (2 hours)","metadata":{}},{"cell_type":"markdown","source":"## Now that we have developed many features, we can create a model based around our dataset. Because we know that our model is going to be dealing with text classification, we must find a model ideal for text classification. After conducting some research, I found a model called 'doc2vec' that can take the mathematical average of the word vector representations of all sentences in the document. I will be borrowing code from the blog post at https://towardsdatascience.com/multi-class-text-classification-model-comparison-and-selection-5eb066197568.","metadata":{}},{"cell_type":"markdown","source":"### We will first begin by labeling each sentence in the document.","metadata":{}},{"cell_type":"code","source":"def label_sentences(corpus, label_type):\n    \"\"\"\n    Gensim's Doc2Vec implementation requires each document/paragraph to have a label associated with it.\n    We do this by using the TaggedDocument method. The format will be \"TRAIN_i\" or \"TEST_i\" where \"i\" is\n    a dummy index of the post.\n    \"\"\"\n    labeled = []\n    for i, v in enumerate(corpus):\n        label = label_type + '_' + str(i)\n        labeled.append(doc2vec.TaggedDocument(v.split(), [label]))\n    return labeled\nX_train, X_test, y_train, y_test = train_test_split(wikipedia_data_copy['Text'], wikipedia_data_copy['End of Paragraph'], random_state=0, test_size=0.3)\nX_train = label_sentences(X_train, 'Train')\nX_test = label_sentences(X_test, 'Test')\nall_data = X_train + X_test","metadata":{"execution":{"iopub.status.busy":"2022-11-09T08:04:57.392647Z","iopub.execute_input":"2022-11-09T08:04:57.393022Z","iopub.status.idle":"2022-11-09T08:04:59.035957Z","shell.execute_reply.started":"2022-11-09T08:04:57.392997Z","shell.execute_reply":"2022-11-09T08:04:59.034601Z"},"trusted":true},"execution_count":127,"outputs":[]},{"cell_type":"markdown","source":"### Then we will initialize the model.","metadata":{}},{"cell_type":"code","source":"model_dbow = Doc2Vec(dm=0, vector_size=300, negative=5, min_count=1, alpha=0.065, min_alpha=0.065)\nmodel_dbow.build_vocab([x for x in tqdm(all_data)])\n\nfor epoch in range(30):\n    model_dbow.train(utils.shuffle([x for x in tqdm(all_data)]), total_examples=len(all_data), epochs=1)\n    model_dbow.alpha -= 0.002\n    model_dbow.min_alpha = model_dbow.alpha","metadata":{"execution":{"iopub.status.busy":"2022-11-09T08:04:59.037589Z","iopub.execute_input":"2022-11-09T08:04:59.038731Z","iopub.status.idle":"2022-11-09T08:18:25.073141Z","shell.execute_reply.started":"2022-11-09T08:04:59.038676Z","shell.execute_reply":"2022-11-09T08:18:25.072444Z"},"trusted":true},"execution_count":128,"outputs":[{"name":"stderr","text":"100%|██████████| 416598/416598 [00:00<00:00, 3586992.15it/s]\n100%|██████████| 416598/416598 [00:00<00:00, 3589313.15it/s]\n100%|██████████| 416598/416598 [00:00<00:00, 3577525.65it/s]\n100%|██████████| 416598/416598 [00:00<00:00, 3462119.54it/s]\n100%|██████████| 416598/416598 [00:00<00:00, 3525241.16it/s]\n100%|██████████| 416598/416598 [00:00<00:00, 3410000.19it/s]\n100%|██████████| 416598/416598 [00:00<00:00, 3512697.45it/s]\n100%|██████████| 416598/416598 [00:00<00:00, 3570143.00it/s]\n100%|██████████| 416598/416598 [00:00<00:00, 3537402.06it/s]\n100%|██████████| 416598/416598 [00:00<00:00, 3480983.13it/s]\n100%|██████████| 416598/416598 [00:00<00:00, 3538197.14it/s]\n100%|██████████| 416598/416598 [00:00<00:00, 3554253.72it/s]\n100%|██████████| 416598/416598 [00:00<00:00, 3530726.03it/s]\n100%|██████████| 416598/416598 [00:00<00:00, 3529763.16it/s]\n100%|██████████| 416598/416598 [00:00<00:00, 3524906.92it/s]\n100%|██████████| 416598/416598 [00:00<00:00, 3461694.29it/s]\n100%|██████████| 416598/416598 [00:00<00:00, 3506501.24it/s]\n100%|██████████| 416598/416598 [00:00<00:00, 3528971.86it/s]\n100%|██████████| 416598/416598 [00:00<00:00, 3570872.60it/s]\n100%|██████████| 416598/416598 [00:00<00:00, 3572500.67it/s]\n100%|██████████| 416598/416598 [00:00<00:00, 3562122.54it/s]\n100%|██████████| 416598/416598 [00:00<00:00, 3425106.55it/s]\n100%|██████████| 416598/416598 [00:00<00:00, 3443696.83it/s]\n100%|██████████| 416598/416598 [00:00<00:00, 3438783.33it/s]\n100%|██████████| 416598/416598 [00:00<00:00, 3517973.34it/s]\n100%|██████████| 416598/416598 [00:00<00:00, 3561955.53it/s]\n100%|██████████| 416598/416598 [00:00<00:00, 3523428.49it/s]\n100%|██████████| 416598/416598 [00:00<00:00, 3482912.04it/s]\n100%|██████████| 416598/416598 [00:00<00:00, 3536593.02it/s]\n100%|██████████| 416598/416598 [00:00<00:00, 3552136.68it/s]\n100%|██████████| 416598/416598 [00:00<00:00, 3536607.33it/s]\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### Next, we will obtain vectors from the model...","metadata":{}},{"cell_type":"code","source":"def get_vectors(model, corpus_size, vectors_size, vectors_type):\n    \"\"\"\n    Get vectors from trained doc2vec model\n    :param doc2vec_model: Trained Doc2Vec model\n    :param corpus_size: Size of the data\n    :param vectors_size: Size of the embedding vectors\n    :param vectors_type: Training or Testing vectors\n    :return: list of vectors\n    \"\"\"\n    vectors = np.zeros((corpus_size, vectors_size))\n    for i in range(0, corpus_size):\n        prefix = vectors_type + '_' + str(i)\n        vectors[i] = model.docvecs[prefix]\n    return vectors\n    \ntrain_vectors_dbow = get_vectors(model_dbow, len(X_train), 300, 'Train')\ntest_vectors_dbow = get_vectors(model_dbow, len(X_test), 300, 'Test')","metadata":{"execution":{"iopub.status.busy":"2022-11-09T08:18:25.074646Z","iopub.execute_input":"2022-11-09T08:18:25.074971Z","iopub.status.idle":"2022-11-09T08:18:27.409782Z","shell.execute_reply.started":"2022-11-09T08:18:25.074935Z","shell.execute_reply":"2022-11-09T08:18:27.408614Z"},"trusted":true},"execution_count":129,"outputs":[]},{"cell_type":"markdown","source":"### ... and get a logistic regression model from our trained features.","metadata":{}},{"cell_type":"code","source":"logreg = LogisticRegression(n_jobs=1, C=1e5)\nlogreg.fit(train_vectors_dbow, y_train)\nlogreg = logreg.fit(train_vectors_dbow, y_train)","metadata":{"execution":{"iopub.status.busy":"2022-11-09T08:18:27.411050Z","iopub.execute_input":"2022-11-09T08:18:27.411281Z","iopub.status.idle":"2022-11-09T08:18:46.805690Z","shell.execute_reply.started":"2022-11-09T08:18:27.411258Z","shell.execute_reply":"2022-11-09T08:18:46.804928Z"},"trusted":true},"execution_count":130,"outputs":[]},{"cell_type":"markdown","source":"## Now that we have our model, we can evaluate how the model performs on our test set through a variety of metrics. Because our dataset is imbalanced (logically, there are many more lines that are not at the end of the paragraph than are at the end of the paragraph), we will prioritize understanding our f1-score; we can still examine our accuracy to make sure that our accuracy is also high since it is another important metric.","metadata":{}},{"cell_type":"code","source":"y_pred = logreg.predict(test_vectors_dbow)\nprint('accuracy: %s' % accuracy_score(y_pred, y_test))\nprint('f1: %s' % f1_score(y_pred, y_test))\n\nprint(\"\\n\")\n\nprint(classification_report(y_test, y_pred))","metadata":{"execution":{"iopub.status.busy":"2022-11-09T08:18:46.807023Z","iopub.execute_input":"2022-11-09T08:18:46.807527Z","iopub.status.idle":"2022-11-09T08:18:47.100354Z","shell.execute_reply.started":"2022-11-09T08:18:46.807498Z","shell.execute_reply":"2022-11-09T08:18:47.099271Z"},"trusted":true},"execution_count":131,"outputs":[{"name":"stdout","text":"accuracy: 0.8672747639622339\nf1: 0.7241493996740613\n\n\n              precision    recall  f1-score   support\n\n       False       0.88      0.95      0.91     91283\n        True       0.82      0.65      0.72     33697\n\n    accuracy                           0.87    124980\n   macro avg       0.85      0.80      0.82    124980\nweighted avg       0.86      0.87      0.86    124980\n\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## After all our work, we can see that we have achieved a total accuracy of 0.868 and an f1 score of 0.727, ensuring that the model we created is reliable for predicting what lines are at the end of a paragraph.","metadata":{}},{"cell_type":"markdown","source":"# Reflection / Next Steps","metadata":{}},{"cell_type":"markdown","source":"I had a lot of fun working on this project and really expanded my machine learning skills. I familiaried myself with many principles that I previously learned and engaged in learning new ones, such as how to connect many files based on the same name and how to analyze a plethora of data. This was my first time starting completely from scratch with a dataset and manually finding ways to add features, which proved to be very rewarding; I also learned how to optimize a model for a text classification task specifically by undergoing research to find an ideal solution. I learned how to experiment with a variety of new models and techniques for machine learning (such as doc2vec) that I know I will use throughout my future ML practices. Most importantly, I learned how to learn new techniques for analyzing machine learning fast and incorporate those techniques throughout my work.\n\nThough I am satisfied with the current work I have done, I can recognize future areas of improvement that I would love to tackle. First, I would like to incorporate a much greater variety of data throughout this program. While I used Wikipedia data because it was plentiful and readily available, Wikipedia articles tend to have similar structures to each other, making it easier for the model to predict when the end of a paragraph is likely to occur. I want to feed a greater variety of data into the model, such as random blog posts, poems, and stories, to diversify the data and allow for there to be many more ways to predict when the end of a paragraph occurs. This would also allow for a greater diversity of voices to be heard so that we may hear a multitude of perspectives and understand how a wide set of people may end paragraphs differently (i.e. within different settings - colloquial blog posts versus formal contracts). Another way to increase the diversity of voices heard would be to analyze more text in more languages; I may take this project further by inputting Ukrainian and Russian language data within the model to then improve linguistic diversity of identifying the end of paragraphs while ensuring I can understand the data I analyze (and maintain an ethical standard). To make this model more applicable to contracts and acceptance letters, I want to work towards creating a database of a variety of these to analyze explicitly, customizing the model for the specific task at hand.\n\nThere are also more features that I would like to experiment with. For example, I noticed that lines at the end of a paragraph tend to have a different \"conclusive\" tone than those that are at the beginning or middle of a paragraph. I want to find a way to extract this tone, such as by using IBM Watson (albeit likely having to pay a fee), to add as a column to the dataset. I also want to experiment with finding ways to algorithmically identify more features that may lead to an end of paragraph indication and experiment with dropping and combining features (for example, having just n columns may lead to greater accuracy than considering all columns when building a model). I want to build a pipeline where I can test many models ideal for text classification and finetune their hyperparameters to truly maximize accuracy.\n\nAs a simple task, I want to grow my machine learning skills so that I can learn to optimize the code within this program as a whole and increase efficiency and runtime wherever possible.\n\nAnother area of possible work is to find a way to create my own machine learning models to optimize the task at hand. While researching how to complete this task, I found an interesting paper from the 2017 International Conference on Information and Communication Technology Convergence titled \"Line-break prediction of hanmun text using recurrent neural networks\". This paper used recurrent neural networks to create NLP models that predicted when Hanmun poems had line breaks. This paper was a fascinating read and inspired me to use its applications and formulas to find a way to create an original model optimized for specifically finding line breaks.\n\nI can foresee some possible limitations with this model, such as that a short line length is not necessarily indicative of being the last line of a paragraph (such as the given acceptance letter that had a paragraph listing the employer, company name, etc on different lines); this is another area to explore with further work.\n\nOverall, this project was thrilling and confirmed my passion for machine learning. I am inspired to continue iterating on this program and I hope to do similar projects to these in the future, analyzing a wide variety of texts and to help serve others.","metadata":{}}]}